{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "922db80a-e34d-422a-8b5b-d09538ca5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imshow('output', img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96f48441-e8f8-49bf-852f-99eb4bdfd260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    "import yaml\n",
    "from yaml.loader import SafeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c1f27d1-f0e1-4056-a38d-da5a75e40193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train']\n"
     ]
    }
   ],
   "source": [
    "# Real-time predictions\n",
    "with open('data.yaml', 'r') as f:\n",
    "    data_yaml = yaml.load(f, Loader = SafeLoader)\n",
    "\n",
    "labels = data_yaml['names']\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad3cb33f-4660-4f4f-87d7-7e0a902c61ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = cv2.dnn.readNetFromONNX('./Model/Model12/weights/best.onnx')\n",
    "yolo.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "yolo.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf77e0f8-b107-4069-bc45-948473835ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./sampletrain.png')\n",
    "img = image.copy()\n",
    "ratio = image.shape[1] / image.shape[0]\n",
    "width = 500\n",
    "height = int(width / ratio)\n",
    "img = cv2.resize(image, (width, height))\n",
    "row, col, d = img.shape\n",
    "\n",
    "# contort image to rectanglular array \n",
    "max_rowcol = max(row,col)\n",
    "inp_image = np.zeros((max_rowcol,max_rowcol,3), dtype = np.uint8)\n",
    "inp_image[0:row, 0:col] = img\n",
    "\n",
    "inp_wid = 640\n",
    "blob = cv2.dnn.blobFromImage(inp_image, (1/255), (inp_wid, inp_wid), swapRB = True, crop = False)\n",
    "yolo.setInput(blob)\n",
    "predict = yolo.forward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f7eae7a-7f2c-4b31-8ce7-0c3c10986ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 25200, 6)\n"
     ]
    }
   ],
   "source": [
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21fbfca8-a636-4ae9-93a9-eeece2cf7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = predict[0]\n",
    "dimensions = []\n",
    "confidences = []\n",
    "classes = []\n",
    "img_w, img_h = inp_image.shape[:2]\n",
    "x_factor = img_w/inp_wid\n",
    "y_factor = img_h/inp_wid\n",
    "\n",
    "for i in range(len(detections)):\n",
    "    row = detections[i]\n",
    "    confidence = row[4] # confid in array is in index 4\n",
    "    if confidence > 0.4:\n",
    "        class_score = row[5:].max()\n",
    "        class_id = row[5:].argmax() \n",
    "        if class_score > 0.25:\n",
    "            cx, cy, w, h = row[0:4]\n",
    "            left = int((cx - 0.5*w)*x_factor)\n",
    "            top = int((cy - 0.5*h)*y_factor)\n",
    "            width = int(w*x_factor)\n",
    "            height = int(h*y_factor)\n",
    "            \n",
    "            box = np.array([left, top, width, height])\n",
    "            confidences.append(confidence)\n",
    "            dimensions.append(box)\n",
    "            classes.append(class_id)\n",
    "\n",
    "dimensions_np = np.array(dimensions).tolist()\n",
    "confidences_np = np.array(confidences).tolist()\n",
    "\n",
    "index_positions = cv2.dnn.NMSBoxes(dimensions_np, confidences_np, 0.25, 0.45).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ece0019a-a99b-4c5f-9bed-f51f3ebb5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in index_positions:\n",
    "    x, y, w, h = dimensions_np[index]\n",
    "    bbox_conf = int(confidences_np[index] * 100)\n",
    "    classes_id = classes[index]\n",
    "    class_name = labels[classes_id]\n",
    "\n",
    "    text = f'{class_name}: {bbox_conf}%'\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "    cv2.rectangle(img, (x,y-30), (x+w, y), (255,255,255), -1)\n",
    "    \n",
    "    cv2.putText(img, text, (x,y-10), cv2.FONT_HERSHEY_COMPLEX, 0.7, (0,0,0), 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b353fe1-36de-4d04-a59c-a089ba6254dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imshow('original', image)\n",
    "cv2.imshow('yolo_pred', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c17d7-0f9d-4fbd-befe-0314d2d6c508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
